from datetime import date

import numpy as np
import pandas as pd
from panel_imputer import PanelImputer

from utils.data_processing import default_impute, min_max_scaling


class VulnerabilityMixin:
    def clip_fill_data(
        self, df_in: pd.DataFrame, resolution: str = "cy", require_all: bool = True
    ) -> pd.DataFrame:
        """
        Function to impute and/or clip data for indicator calculation. Ensures consistent end date for all columns in df_in.
        To do so, it checks the data availability for each indicator and each time step (based on the source resolution). It
        then either forward fills with last known value if the data across all columns (require_all=False) or all of the
        indicators individually have at least 25% coverage (hardcoded into helper functions at the moment) and set all data
        after to NA. Default imputation (which fills empty data in between or before the last available data) should be
        performed before using this function.

        Parameters
        ----------
        df_in: dataframe to process
        resolution: data resolution. Takes 'cy' for country-year or 'gq' for grid-quarter.
        require_all: flag to whether all

        """

        # TODO: either here on in the availability functions - perform check on wether default_impute was performed

        # create empty dataframe with input structure
        df = pd.DataFrame(index=df_in.index, columns=df_in.columns, dtype=np.float64)
        if resolution == "cy":
            # check data availability
            df_available = self._indicator_availability_country(df_in, require_all)
            # perform imputation only on a copy for when availability criteria are met to preserve NAs where this is not the case
            df_update = df_in.loc[
                (slice(None), df_available[df_available.check_passed].index), slice(None)
            ].copy()
            imputer = PanelImputer(
                time_index="year",
                location_index="iso3",
                imputation_method="interpolate",
                interp_method="slinear",
                tail_behavior="fill",
            )
        elif resolution == "gq":
            # check data availability
            df_in_temp = df_in.copy()  # we don't want to modify input for this
            # create (date)time column as a helper column and check data availability
            df_in_temp["time"] = list(
                df_in.reset_index().apply(
                    lambda x: date(int(x["year"]), int(x["quarter"] * 3 - 2), 1), axis=1
                )
            )
            df_available = self._indicator_availability_grid(df_in_temp, require_all)
            # perform imputation only on a copy for when availability criteria are met to preserve NAs where this is not the case
            check_passed = list(df_in_temp.time.isin(df_available[df_available.check_passed].index))
            df_update = df_in_temp.loc[check_passed].copy()
            imputer = PanelImputer(
                time_index=["year", "quarter"],
                location_index="pgid",
                imputation_method="interpolate",
                interp_method="slinear",
                tail_behavior="fill",
            )
        else:
            raise ValueError('parameter "resolution" needs to be one of ["cy", "gq"]')
        df_update: pd.DataFrame = imputer.fit_transform(df_update)  # type: ignore
        # update input df
        df.update(df_update)
        return df

    def _indicator_availability_country(
        self, df_in: pd.DataFrame, require_all: bool
    ) -> pd.DataFrame:
        """
        Helper function for clip_fill_data that creates a df with data availability for all time steps and columns in df_in.
        Works for country-year level.
        """
        df_available = pd.DataFrame(
            index=range(int(df_in.index.get_level_values("year").min()), date.today().year + 1),
            columns=["check_passed"],
        )
        df = df_in.reorder_levels([1, 0]).sort_index().copy()
        for year in df_available.index:
            check_passed = True
            try:
                mean_nas = df.loc[year].isna().sum() / len(df.loc[year])
                # condition for passing: all need to have some data at least and the average na share is less than .75
                if require_all:
                    if any(mean_nas == 1) or mean_nas.mean() > 0.75:
                        check_passed = False
                else:
                    if mean_nas.mean() > 0.75:
                        check_passed = False
            except KeyError:
                # df passed may not go until current year
                check_passed = False
            df_available.at[year, "check_passed"] = check_passed
        return df_available

    def _indicator_availability_grid(self, df_in: pd.DataFrame, require_all: bool) -> pd.DataFrame:
        """
        Helper function for clip_fill_data that creates a df with data availability for all time steps and columns in df_in.
        Works for grid-quarter level and requires a time column with date objects.
        """
        df_available = pd.DataFrame(index=df_in["time"].unique(), columns=["check_passed"])
        df = df_in.copy()
        df = df.set_index("time", append=True).reset_index(["year", "quarter"], drop=True)
        df = df.reorder_levels([1, 0]).sort_index()
        for time in df_available.index:
            check_passed = True
            try:
                mean_nas = df.loc[time].isna().sum() / len(df.loc[time])
                # condition for passing: all need to have some data at least and the average na share is less than .75
                if require_all:
                    if any(mean_nas == 1) or mean_nas.mean() > 0.75:
                        check_passed = False
                else:
                    if mean_nas.mean() > 0.75:
                        check_passed = False
            except KeyError:
                # df passed may not go until current year
                check_passed = False
            df_available.at[time, "check_passed"] = check_passed
        return df_available


class HDIMixin:
    def combine_subnational_national_hdi(
        self, df: pd.DataFrame, df_hdi: pd.DataFrame, df_shdi: pd.DataFrame
    ):
        # rename to shdi names
        matching_dict = {
            "le_index": "healthindex",
            "edu_index": "edindex",
            "eys": "esch",
            "mys": "msch",
            "le": "lifexp",
        }
        shdi_cols = df_shdi.columns
        df_hdi = df_hdi.rename(columns=matching_dict)
        df_yearly = default_impute(df_hdi, "year", "iso3")
        for col in shdi_cols:
            df_yearly[f"{col}_change"] = (df_yearly.groupby("iso3")[col].pct_change(1) + 1).shift(
                -1
            )
            # hdi data can be kindof spotty and reality should be somewhat stable, doing some outlier control
            quantiles = df_yearly[f"{col}_change"].quantile([.01, .99]).to_list()
            df_yearly[f"{col}_change"] = df_yearly[f"{col}_change"].clip(*quantiles)
        df = pd.concat([df, df_shdi], axis=1)
        # impute subnational data based on cahnge in national indicator
        df_update = pd.merge(
            df.xs(4, level="quarter", drop_level=False).reset_index(),
            df_yearly[[c for c in df_yearly.columns if "change" in c]],
            left_on=["year", "iso3"],
            right_on=["year", "iso3"],
            how="left",
        ).set_index(["pgid", "year", "quarter"])
        for col in shdi_cols:
            df_update[col] = (df_update[col] * df_update[f"{col}_change"]).shift(1).round(3)
        # reset index cols to 0-1 after imputation as it may not quite respect the fixed boundaries
        index_cols = [col for col in ["edindex", "healthindex"] if col in shdi_cols]
        for col in index_cols:  # should be just one
            df_update[col] = min_max_scaling(df_update[col], minv=0, maxv=1)
        df.update(df_update[shdi_cols], overwrite=False)
        for col in shdi_cols:
            df[col] = default_impute(df[col])
        return df
