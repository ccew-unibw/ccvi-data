import numpy as np
import pandas as pd
from panel_imputer import PanelImputer

from base.objects import Indicator, ConfigParser, GlobalBaseGrid
from base.datasets import WBData, IMFGDPData, WPPData, NTLData, WorldPopData
from utils.data_processing import default_impute, min_max_scaling
from utils.index import get_quarter


class VulSocioeconomicDeprivation(Indicator):
    def __init__(
        self,
        config: ConfigParser,
        grid: GlobalBaseGrid,
        pillar: str = "VUL",
        dim: str = "socioeconomic",
        id: str = "deprivation",
    ):
        """Params defining indicator's place in index set to designed hierarchy by default"""
        self.wb = WBData(config=config)
        self.imf = IMFGDPData(config=config)
        self.wpp = WPPData(config=config)
        self.ntl = NTLData(config=config)
        self.worldpop = WorldPopData(config=config)
        super().__init__(pillar=pillar, dim=dim, id=id, config=config, grid=grid)

    def load_data(self) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
        # self.ntl.load_data()
        # self.worldpop.load_data()
        wb_indicators = {
            "NY.GDP.MKTP.PP.CD": "gdp_ppp",  # GDP, PPP (current international $)}
        }
        df_wb = self.wb.load_data(wb_indicators)
        df_imf = self.imf.load_data()
        df_wpp = self.wpp.load_data()
        return df_wb, df_imf, df_wpp

    def preprocess_data(
        self, input_data: tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]
    ) -> pd.DataFrame:
        df_wb, df_imf, df_wpp = input_data
        df_imf = self.imf.preprocess_data(df_imf)
        df_wpp = self.wpp.preprocess_wpp(df_wpp)
        df_gdp = self._merge_gdp_data(df_wb, df_imf)
        df_gdp = self._add_pc_values(df_gdp, df_wpp)
        df_ntl = self.ntl.preprocess_yearly(self.grid)
        df_ntl["ntl_log"] = df_ntl["ntl_median"].apply(lambda x: np.log10(1 + x))
        df_worldpop_yearly = self.worldpop.process_yearly_grid_aggregates(self.grid)

        imputer = PanelImputer(
            time_index="year",
            location_index="iso3",
            imputation_method="interpolate",
            interp_method="slinear",
            tail_behavior="extrapolate",
            parallelize=True,
        )
        df_gdp: pd.DataFrame = imputer.fit_transform(df_gdp)  # type: ignore
        df_preprocessed_yearly = df_ntl.reset_index().merge(df_gdp, how="left", on=["iso3", "year"])

        df_preprocessed_yearly = df_preprocessed_yearly.merge(
            df_worldpop_yearly["pop_count"], on=["pgid", "year"], how="left"
        )
        # country pop counts based on grids
        pop_count = (
            df_worldpop_yearly.groupby(["iso3", "year"])["pop_count"]
            .sum()
            .replace(0, np.nan)
            .rename("pop_count_country")
        )
        df_preprocessed_yearly = (
            df_preprocessed_yearly.reset_index()
            .merge(pop_count, how="left", on=["iso3", "year"])
            .set_index(["pgid", "year"])
        )
        return df_preprocessed_yearly

    def create_indicator(self, df_yearly: pd.DataFrame) -> pd.DataFrame:
        # add 1 to ntl values so "empty" (masked) ntl cells with value 0 get country average
        df_yearly[self.composite_id] = (
            df_yearly["gdp_ppp"] * (df_yearly["ntl_log"] + 1) / df_yearly["pop_count_country"]
        )
        df_yearly[self.composite_id] = df_yearly[self.composite_id].apply(np.log1p)
        df_yearly[f"{self.composite_id}_raw"] = df_yearly["gdp_ppp_pc"]
        return df_yearly

    def normalize(self, df_indicator_yearly: pd.DataFrame) -> pd.DataFrame:
        thresholds_gdp = df_indicator_yearly.loc[
            (slice(None), slice(None, 2020)), self.composite_id
        ].quantile([0.01, 0.99])
        df_indicator_yearly[self.composite_id] = min_max_scaling(
            df_indicator_yearly[self.composite_id],
            minv=thresholds_gdp.iloc[0],
            maxv=thresholds_gdp.iloc[1],
        )
        # merge with base df and linear interpolate to quarters
        df_base = self.create_base_df()
        df_indicator_yearly["quarter"] = 4
        df_indicator_yearly = df_indicator_yearly.set_index("quarter", append=True).sort_index()
        df_normalized = df_base.merge(
            df_indicator_yearly[[self.composite_id]], how="left", left_index=True, right_index=True
        )

        # higher values = less vulnerable -> reverse scale
        df_normalized[self.composite_id] = 1 - df_normalized[self.composite_id]
        df_normalized = default_impute(df_normalized[self.composite_id])
        return df_normalized[[self.composite_id]]

    def add_raw_value(
        self, df_indicator: pd.DataFrame, df_preprocessed: pd.DataFrame
    ) -> pd.DataFrame:
        df_preprocessed[f"{self.composite_id}_raw"] = df_preprocessed["gdp_ppp_pc"]
        df_preprocessed["quarter"] = 4
        df_yearly = df_preprocessed.set_index("quarter", append=True).sort_index()

        df_indicator = df_indicator.merge(
            df_yearly[[f"{self.composite_id}_raw"]], how="left", left_index=True, right_index=True
        )
        df_indicator[f"{self.composite_id}_raw"] = default_impute(
            df_indicator[f"{self.composite_id}_raw"]
        )
        return df_indicator

    def _merge_gdp_data(
        self,
        df_wb: pd.DataFrame,
        df_imf: pd.DataFrame,
    ) -> pd.DataFrame:
        """
        Updates World Bank dataframe with IMF GDP data if no World Bank data is available to increase coverage
        """
        base_iso3 = list(self.grid.load().iso3.unique())
        df_base_yearly = pd.DataFrame(data=base_iso3, columns=["iso3"])
        df_base_yearly["year"] = [
            np.arange(self.global_config["start_year"], get_quarter("last").year).tolist()
            for i in df_base_yearly.index
        ]
        df_base_yearly = df_base_yearly.explode("year")
        # start by merging with world bank data
        df_merged = df_base_yearly.merge(df_wb.reset_index(), how="left", on=["iso3", "year"])
        df_merged["year"] = df_merged.year.astype(int)
        df_merged = df_merged.set_index(df_wb.index.names).sort_index()
        # update with imf data
        for iso3 in df_base_yearly.reset_index()["iso3"].unique():
            temp_df = df_merged.loc[iso3]
            try:
                temp_df_imf = df_imf.xs(iso3, level="iso3", drop_level=False)
            except KeyError:
                continue
            # where there is no(!) or not enough world bank data to impute, use imf data if available
            # only fill if more than 3 missing - bit arbitrary but oh well
            if sum(temp_df["gdp_ppp"].isna()) > 3:
                # if we fill, we want to use all imf data for consistency
                df_merged.update(temp_df_imf[["gdp_ppp"]], overwrite=True)

        return df_merged.sort_index()[["gdp_ppp"]]

    def _add_pc_values(self, df_yearly: pd.DataFrame, df_wpp: pd.DataFrame) -> pd.DataFrame:
        """
        Adds country-year-level population data and calculates per-capita values based on preprocessed UN Population Estimates
        """
        df = pd.merge(
            df_yearly, df_wpp[["pop_total"]], how="left", left_index=True, right_index=True
        )
        for col in df_yearly.columns:
            df[f"{col}_pc"] = df[col] / df.pop_total
        return df


if __name__ == "__main__":
    config = ConfigParser()
    grid = GlobalBaseGrid(config)
    indicator = VulSocioeconomicDeprivation(config=config, grid=grid)
    indicator.run()
