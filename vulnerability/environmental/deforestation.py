import os
import time
from typing import Literal

from joblib import Parallel, delayed
import numpy as np
import pandas as pd
from rich.progress import Progress, TimeElapsedColumn
from tqdm import tqdm
import xarray as xr
import rioxarray as rxr

from base.datasets import GFCData
from base.objects import Indicator, ConfigParser, GlobalBaseGrid
from utils.data_processing import default_impute
from utils.spatial_operations import pgid_to_coords


class VulEnvironmentalDeforestation(Indicator):
    def __init__(
        self,
        config: ConfigParser,
        grid: GlobalBaseGrid,
        pillar: str = "VUL",
        dim: str = "environmental",
        id: str = "deforestation",
    ):
        """Params defining indicator's place in index set to designed hierarchy by default"""
        self.gfc = GFCData(config=config)
        super().__init__(pillar=pillar, dim=dim, id=id, config=config, grid=grid)
        
    def load_data(self) -> None:
        self.gfc.load_data(self.grid)
        return
    
    def preprocess_data(self, *args, **kwargs) -> None:
        """No preprocessing necessary"""
        assert self.gfc.data_loaded
        return
    
    def create_indicator(self, *args, **kwargs) -> pd.DataFrame:
        df = self.create_base_df()
        years = list(range(self.global_config["start_year"], int(self.gfc.version[4:8]) + 1))
        try: 
            df_prior = self.storage.load()
            if not df.reset_index()["year"].max() == max(years):
                raise FileNotFoundError
            self.console.print("Existing indicator values for latest GFC version loaded from storage. No further processing required.")
            df = df.merge(df_prior, how="left", left_index=True, right_index=True)
        except FileNotFoundError:
            df[self.composite_id] = np.nan
            file_dict = self.gfc.get_dict_files(self.grid)
            all_pgids = df.index.get_level_values("pgid").unique()
            with Progress(
                *Progress.get_default_columns(),
                TimeElapsedColumn(),
                console=self.console,
                speed_estimate_period=120
            ) as progress:
                processing_task = progress.add_task("Calculating grid tree loss aggregates", total = len(file_dict))
                for tile in file_dict:
                    pgids_tile = self.gfc.get_pgids_for_tile(tile, all_pgids)
                    assert pgids_tile is not None
                    losses = self._calculate_tile_losses(pgids_tile, file_dict[tile], years)
                    if losses is None:
                        progress.update(processing_task, advance=1)
                        continue
                    elif losses == "all_zero":
                        df.loc[(pgids_tile, slice(None), slice(None)), self.composite_id] = 0
                        self.console.print("No loss data available despite treecover data.. assigning no loss to all pgids in tile:", tile)
                    else:
                        for i, pgid in enumerate(pgids_tile):
                            for year in losses[i]:
                                # assign to last quarter of year and impute between later
                                df.at[(pgid, year, 4), self.composite_id] = losses[i][year]
                    progress.update(processing_task, advance=1)
            df.to_parquet("test.parquet")
            df = default_impute(df)
        return df
                        
    def normalize(self, df_indicator:pd.DataFrame) -> pd.DataFrame:
        return df_indicator[[c for c in df_indicator.columns if self.composite_id in c]]

    def _calculate_tile_losses(self, pgids_tile: list[int], tile_files: dict, years: list[int]) -> list[dict[int, float]] | None | Literal["all_zero"]:
        # no data available
        if tile_files is None:
            return None
        if tile_files["lossyear"] is None:
            # no loss and no treecover is coded as NA - no action
            if rxr.open_rasterio(tile_files["treecover2000"]).sum() != 0:
                # no loss data but treecover gets a zero (just one case in the data)
                return "all_zero"
            else: 
                return None
        # read & combine tile data
        assert all(layer is not None for layer in tile_files), "Unexpected None in file_dict"
        das = [rxr.open_rasterio(tile_files[layer]).rename(layer) for layer in tile_files]
        ds = xr.merge(das, compat="identical")
        with Parallel(n_jobs=-2) as parallel:
            losses = parallel(
                delayed(self._get_cell_tree_loss_share)(pgid, years, ds) for pgid in pgids_tile
            )
        return losses
                
    @staticmethod              
    def _get_cell_tree_loss_share(pgid: int, years: list[int], ds:xr.Dataset) -> dict[int, float]:
        y, x = pgid_to_coords(pgid)
        ds_cell = ds.sel(x=slice(x-.25, x+.25), y=slice(y+.25, y-.25))
        # percent of grid cell land covered by trees
        cell_cover = ds_cell.treecover2000.where(ds_cell.datamask == 1).mean() / 100
        yearly_losses = {}
        for year in years:
            # dummy loss layer
            losses = xr.where((ds_cell.lossyear > 0) & (ds_cell.lossyear <= int(str(year)[2:])), 1, 0)
            # account for differently covered pixels
            treecover_lost = (losses * ds.treecover2000).sum() / ds_cell.treecover2000.sum()
            # use percent cover as adjustment factor for cell
            treecover_adjusted = treecover_lost * cell_cover
            yearly_losses[year] = treecover_adjusted.item()
        return yearly_losses
    
if __name__ == "__main__":
    config = ConfigParser()
    grid = GlobalBaseGrid(config)
    indicator = VulEnvironmentalDeforestation(config=config, grid=grid)
    indicator.run()