import geopandas as gpd
from panel_imputer import PanelImputer
import pandas as pd

from base.datasets import AqueductData
from base.objects import Indicator, ConfigParser, GlobalBaseGrid
from utils.data_processing import create_data_structure_yearly


class VulEnvironmentalWater(Indicator):
    def __init__(
        self,
        config: ConfigParser,
        grid: GlobalBaseGrid,
        pillar: str = "VUL",
        dim: str = "environmental",
        id: str = "water",
    ):
        """Params defining indicator's place in index set to designed hierarchy by default"""
        self.aqueduct = AqueductData(config=config)
        super().__init__(pillar=pillar, dim=dim, id=id, config=config, grid=grid)

    def load_data(self) -> tuple[pd.DataFrame, gpd.GeoDataFrame]:
        data = self.aqueduct.load_data()
        return data

    def preprocess_data(
        self, data: tuple[pd.DataFrame, gpd.GeoDataFrame]
    ) -> tuple[gpd.GeoDataFrame, pd.DataFrame]:
        gdf = self.aqueduct.preprocess_data_waterstress(*data)
        df_matching = self.aqueduct.match_aqueduct_grid(gdf, self.grid)
        return gdf, df_matching

    def create_indicator(
        self, dfs_preprocessed: tuple[gpd.GeoDataFrame, pd.DataFrame]
    ) -> pd.DataFrame:
        df_base = self.create_base_df()
        fp_aqu = self.aqueduct.data_config["aqueduct"]
        aqu_version = fp_aqu[fp_aqu.rfind("/") + 1 :]
        filename = f"{aqu_version}_storage"
        try:
            if self.regenerate["preprocessing"]:
                raise FileNotFoundError
            df = self.storage.load("processing", filename)
            self.console.print(
                f"Existing indicator data based on current Aqueduct input {aqu_version} loaded from storage."
            )
        except FileNotFoundError:
            gdf, df_matching = dfs_preprocessed
            df_preprocessed = self.aqueduct.calculate_grid_values(gdf, self.grid, df_matching)
            df = create_data_structure_yearly(
                self.grid.load(), self.global_config["start_year"], 2030
            )
            df_preprocessed["quarter"] = 4
            df_preprocessed = df_preprocessed.set_index("quarter", append=True).sort_index()
            df_preprocessed = df_preprocessed.drop(columns=["lat", "lon", "iso3"])
            df = df.merge(df_preprocessed, how="left", on=["pgid", "year", "quarter"])
            imputer = PanelImputer(
                time_index=["year", "quarter"],
                location_index="pgid",
                imputation_method="interpolate",
                interp_method="slinear",
                tail_behavior=["fill", "None"],
                parallelize=True,
                parallel_kwargs={"n_jobs": -2, "verbose": 1},
            )
            df: pd.DataFrame = imputer.fit_transform(df)  # type: ignore
            self.storage.save(df, "processing", filename)
        df_indicator = pd.concat([df_base, df[["bws_raw"]]], join="inner", axis=1)
        df_indicator = df_indicator.rename(columns={"bws_raw": self.composite_id})
        return df_indicator

    def normalize(self, df_indicator: pd.DataFrame) -> pd.DataFrame:
        """No further normalization necessary."""
        return df_indicator[[c for c in df_indicator.columns if self.composite_id in c]]


# this is possible by adding the root folder as the PYTHONPATH var in .env
if __name__ == "__main__":
    config = ConfigParser()
    grid = GlobalBaseGrid(config)
    indicator = VulEnvironmentalWater(config=config, grid=grid)
    indicator.run()
