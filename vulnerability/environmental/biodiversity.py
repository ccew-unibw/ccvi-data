from datetime import date

import numpy as np
from panel_imputer import PanelImputer
import pandas as pd
import xarray as xr

from base.datasets import BIIData
from base.objects import Indicator, ConfigParser, GlobalBaseGrid
from utils.data_processing import create_custom_data_structure, min_max_scaling
from utils.spatial_operations import coords_to_pgid, s_ceil


class VulEnvironmentalBiodiversity(Indicator):
    def __init__(
        self,
        config: ConfigParser,
        grid: GlobalBaseGrid,
        pillar: str = "VUL",
        dim: str = "environmental",
        id: str = "biodiversity",
    ):
        """Params defining indicator's place in index set to designed hierarchy by default"""
        self.bii = BIIData(config=config)
        super().__init__(pillar=pillar, dim=dim, id=id, config=config, grid=grid)

    def load_data(self) -> xr.Dataset:
        ds = self.bii.load_data()
        return ds

    def preprocess_data(self, ds: xr.Dataset) -> pd.DataFrame:
        df = ds.to_dataframe().reset_index()
        df["pgid"] = df.apply(lambda x: coords_to_pgid(x.lat, x.lon), axis=1).to_list()
        df = df.rename(columns={"time": "year"})
        df["quarter"] = 4
        df = df.set_index(["pgid", "year", "quarter"]).sort_index()
        # only keep cells in base grid
        pgids = grid.load().index
        # limit time and merge to quaterly data structure - data comes every 5 years
        # set start to 2000 to use 2000-2020 baseline
        min_year = 2000
        max_year = int(s_ceil(date.today().year, s=5))
        df = df.loc[(pgids, slice(min_year, max_year)), slice(None)]
        df_base = create_custom_data_structure(self.grid.load(), min_year, max_year)
        df = df_base.merge(df["cellpbii_0p5"], how="left", left_index=True, right_index=True)
        # set NAs correctly
        df["cellpbii_0p5"] = df["cellpbii_0p5"].replace(0, np.nan)
        # interpolate to quarters
        imputer = PanelImputer(
            time_index=["year", "quarter"],
            location_index="pgid",
            imputation_method="interpolate",
            interp_method="slinear",
            tail_behavior="None",
            parallelize=True,
            parallel_kwargs={"n_jobs": -2, "verbose": 1},
        )
        df: pd.DataFrame = imputer.fit_transform(df)  # type: ignore
        return df

    def create_indicator(self, df_preprocessed: pd.DataFrame) -> pd.DataFrame:
        df_indicator = self.create_base_df()
        df_indicator = df_indicator.merge(
            df_preprocessed["cellpbii_0p5"], how="left", left_index=True, right_index=True
        )
        # check to ensure indicator was fully covered by imputed time range - not all na
        assert not df_indicator["cellpbii_0p5"].isna().groupby(["year", "quarter"]).all().any()
        df_indicator = df_indicator.rename(columns={"cellpbii_0p5": f"{self.composite_id}_raw"})
        df_indicator[self.composite_id] = 1 - df_indicator[f"{self.composite_id}_raw"]
        return df_indicator

    def normalize(self, df_indicator: pd.DataFrame) -> pd.DataFrame:
        upper_threshold = df_indicator.loc[
            (slice(None), slice(None, 2020)), self.composite_id
        ].quantile(0.99)
        df_indicator[self.composite_id] = min_max_scaling(
            df_indicator[self.composite_id], maxv=upper_threshold
        )
        return df_indicator[[c for c in df_indicator.columns if self.composite_id in c]]


# this is possible by adding the root folder as the PYTHONPATH var in .env
if __name__ == "__main__":
    config = ConfigParser()
    grid = GlobalBaseGrid(config)
    indicator = VulEnvironmentalBiodiversity(config=config, grid=grid)
    indicator.run()
